%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is the template for submission to HPCA 2016
% The cls file is a modified from  'sig-alternate.cls'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{sig-alternate} 
\usepackage{mathptmx} % This is Times font

\usepackage{fancyhdr}
%\usepackage[normalem]{ulem}
\usepackage[hyphens]{url}
%\usepackage{algorithmicx,algorithm}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{framed}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{subfig}

%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\newcommand{\hpcasubmissionnumber}{NaN}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\todo}[1]{\begin{framed}\textcolor{red}{TODO: #1}\end{framed}}
\fancypagestyle{firstpage}{
  \fancyhf{}
\setlength{\headheight}{50pt}
\renewcommand{\headrulewidth}{0pt}
  \fancyhead[C]{\normalsize{HPCA 2016 Submission
      \textbf{\#\hpcasubmissionnumber} \\ Confidential Draft: DO NOT DISTRIBUTE}} 
  \pagenumbering{arabic}
}  

\newtheorem{lemma}{Lemma}

%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\title{Topology-aware Allocation Policies for Jellyfish } 
\author{Jose A. Pascual, Javier Navaridas, Alejandro Erickson and Ian }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle
\thispagestyle{firstpage}
\pagestyle{plain}

\begin{abstract}



\end{abstract}

\section{Introduction}
\label{introduction}

Jellyfish topology \cite{jellyfish} has been recently proposed as a high bandwidth and low latency interconnect for large scale data centers and HPC systems. In opposite to recenctly proposed server-centric datacenter networks (DCN), jellyfish is an indirect (switch-centric) network in which the servers are connected to the switches. This network is a \textit{degree-bounded} random regular graph (RRG) among the top-of-rack (ToR) switches, in which all the nodes have the same degree, are bidirectional and are connected randomly. RRGs also provide other desiderable properties for an interconnect such as low diameter, high connectivity among nodes and easy incremental expansion.

As stated in the original paper \cite{jellyfish}, routing in jellyfish is a challenge. Although jellyfish provides high connectivity among switches, classical routing policies are not able to exploit the path diversity offered. In that work the authors evaluated two well-known routing policies, shortest path (SP) and Equal-cost Multi-path (ECMP), assesing that the use of the shortest paths does not provide enough path diversity to utilize the full capacity of the network. This issue was solved using the K-Shortest Path (KSP) \cite{yen} routing policy that uses more paths at the cost of being longer. Although KSP perfoms well compared to SP and ECMP, the author in \cite{llksp} showed that jellyfish has several features that make it ineffective. In particular they stated the possibly large number of source-destinations (SD) pairs that will share the same K shortest-paths and the random number of short paths between each pair of switches. 

These works have studied jellyfish both theoretically, puting bounds to topological properties, and empirically evaluating the performance of several communication patterns. However none of them have consider the natural scenario in which this topology could be used: data centers or HPC centers where many applications run concurrently. To the best of our knowledge, there is no work devoted to evaluate the performance of such applications in this topology. The assignemnt of resources to application has been widely studied in the context of HPC. Those works clearly differenciate three stages: selection of the application to be executed, allocation of the resources to that application and mapping of the taks that compose the application to the physical servers. 

The objective of this work is the evaluation of existing allocation policies applied to jellyfish in multi-application scenarios. We will see how these policies do not perform well in jellyfish due to the random nature of this topology. Because of that, we will apply ideas taken from the HPC world and adapt them to the particularisms of jellyfish. In particular we want to define concepts of locality to jellyfish. In addition we will extend the definition of contiguity and convexity to jellyfish. These policies should improve the performance of applications executed on jellyfish. However, contiguity can severely affects system utilization. this drawback will also be studied.

The evaluation of the allocation policies has been carried out using extensive simulation with a representative mix of parallel application. Results show that tradicional and simple allocation strategies do not take advantadge of the characteristics of jellyfish. Moreover we will se how locality-aware policies can take advantadge of those properties improving the performance of applications running concurrently. In particulae locality and contiguous policies ..., We will also evaluate the drawbacks.... 

The rest of the paper is organized as follow. Section \ref{background} introduces jellyfish and communication patterns used thorough the paper. We continue in Section \ref{allocation} analyzing simple allocation policies for jellyfish introducing in Sections \cite{locality} and \cite{contiguity} the proposed policies. The results are presented and analyzed in Section \cite{results} concluding in Section \ref{conclusion} with some conlucsions and future lines of work.

\section{Background}
\label{background}

In this section we describe thoroughly the jellyfish topology and give some definitions and properties that will be used in the rest of the paper. Furthermore, we describe the four routing policies developed for jellyfish asessing the pros and cons of each one of them.

\subsection{Jellyfish topology}
\label{subsec:jellyfish}

Jellyfish is a network topology in which the switches are connected randomly. We denote jellyfish as RRG(N,k,r) where N is the number of switches, k is the number of ports of the switches and r is the number of ports used to connect to other switches.  
\begin{figure}[t]
    \centering 
    \includegraphics[width=\linewidth]{figures/jellyfish.eps}
    \caption{}
    \label{fig:jellyfish}
\end{figure}


\subsection{Routing policies}
\label{subsec:routing}

The jellyfish topology provides high path diversity between any pair of servers. This is one of the characteristic that makes this topology so appealing to execute parallel workloads. As we have seen, there exists a lot of possible paths among physical servers to carry out the communications. This is the reason why the chosing of a routing policy is so important in jellyfish in order to avoid contention in network links. There exist only four routing policies proposed and evaluated for jellyfish. Next, we will analize these policies stating the improvements of one against the others.

\begin{itemize}
    \item Shortest Path (SP):
    \item Equal-Cost Multi-Path (ECMP):
    \item K-Shortest Path:
    \item Limited Length Spread K-shortest Path (LLKSR):
\end{itemize}

\subsection{Workloads and performance metric}
\label{subsec:workloads}

\begin{itemize}
    \item Nearest neighbor:
    \item Collective:
    \item: Permutation and shift pattern:
\end{itemize}

\section{Allocation in Jellyfish}
\label{allocation}

When an application is submitted to be executed, the allocator is in charge of finding the appropiate set of resources to place it. There are many works that propose allocation policies for other topologies such as meshes, tori \cite{tori} \cite{toritree}, or fattrees \cite{toritree} \cite{trees}, but, to the best of our knowledge, not for jellyfish. Only in \cite{llksp} the authors use some simple mono-application allocation policies without taking into account how these policies behave when multiple application run concurrently. In this section we describe and analize those policies adding a new version of one of them due to random structure of jellyfish.

In order to define the allocation policies we must first assign assign a node ordering to the servers and switches that compose the network. Due to the random structure of jellyfish, we first define order the switches and then, inside each switch, we order the server consecutively.

\begin{itemize}
    \item Sequential: The tasks are assigned to the servers consecutively using the identity function.
        \begin{equation}
            \pi:T \rightarrow P\\
            \pi(t_i)=p_i
        \end{equation}
    \item Random: The tasks of the application are assigned to the servers uniformly at random.
        \begin{equation}
            \pi:T \rightarrow P\\
            \pi(t_i)=p_j where p_j is selected at random
        \end{equation}
    \item Random$^*$: This is a special version of the previouly presented policies. In this case we select a switch uniformy at random and then we map (k-r) tasks to the servers direcctly connected to it. 
        \begin{equation}
            \pi:T \rightarrow P\\
            \pi(t_i)=p_j where p_j is selected at random
        \end{equation}
\end{itemize}

\begin{lemma}

\end{lemma}
%The first two policies were evaluated in \cite{llksr} using different communication patterns mapped to the whole system. Using this configuration, the authors evaluated performance using only one application. 

%Results showed that, in average, the sequential policy performs the best. This results is expected because it maintains certain level of locality at a switch level. for some patterns such as  the random policy performs better than the sequential version.      


%\begin{figure}[t]
%  \begin{tikzpicture}
%    \input{plots/plot_dynamic_all2one}     
%  \end{tikzpicture}
%  \caption{Completion time in second employed to process three traffic patterns comparing.}
%\label{fig:plot-dynamic}
%\end{figure}


\subsection{One application's Link utilization}
\label{linkutilization1app}

The development of new routing policies for jellyfish was motivated due to the incapacity of classic policies to take advantadge of the high number of paths connecting every pair of switches. As a results, these policies, such as ksp or llskr, provide a great diversity for chosing paths connecting every pair of communicative severs. However, these policies have been only evaluated in mono-application scenarios where different applications do not compete for the use of the network resources. It is in those scenarios, where these policies could degrade the performance of the applications due to the high number of links used and hence, the increase share of the network links. In addition, the lack of causality in the communications used in those evaluations, does not represent the execution of real applications and , as we will see, it is an important performance facto in multi-applications scenarios.

Let us start analyzing the number of links that an application composed of 64 tasks uses when performing all-to-all communications in networks with different number and types of switches. In particular we have used those summarized in Table \ref{table:network_parameters}. We have used sequential and random allocations, although the results are almost identical, we only have represented the former. The results will give us a hint of how much interference one application could create in the network and therefore affect the performance of other applications. Results are depicted in Figure \ref{fig:link_usage}. 

\input{tables/topologies.tex}

As we can see in Figure \ref{fig:percent_size} the number of used links is determined by the routing policy. The 65-task application in the smaller network uses all the links regardless of the used routing policy. However, as the size of the network increases, the number of used links also increases except for SP (XXX data). As a result, SP will generate less interference with other applications but, at the same time, provide less path diversity that could result in higher contention in the links and therefore less performance.

\begin{figure*}[t]
    \centering 
    \subfloat[Networks with differen size.]{\label{fig:percent_size}{\includegraphics[width=\columnwidth]{data/nlinks_used/graph_percent_all2all.eps}}}
    \subfloat[Networks with different connectivity.]{\label{fig:percent_r}{\includegraphics[width=\columnwidth]{data/nlinks_used/graph_percent_all2all_r.eps}}}
    \caption{Percent of used links by a 64-task all-to-all application using a sequential allocation}
    \label{fig:link_usage}
\end{figure*}

Regarding the other policies, it is clear that  


\subsection{Multiple application's link utilization}
\label{linkutilizationmultiapp}

After measuring the way the routing policies affect the to the number of used links by one application let us see the influence of the routing policies in multi-application scenarios. To do so, we run multiple applications concurrently and measure the number of links shared by how mnay applications. These results allow us to quantify how much interference will generate each routing policy. The results are depicted in Figure \ref{fig:link_usage_multiapp} where the execution of 32 concurrent 64-task applications in a RRG(2048,32,31) network is represented.   

\begin{figure}[h]
    \centering 
    \includegraphics[width=\linewidth]{data/nlinks_used/graph_multiapp_all2all.eps}
    \caption{Number of shared links used by multiple applications when running an all-to-all communication pattern using different routing policies.}
    \label{fig:link_usage_multiapp}
\end{figure}

As espected, SP creates the lower contention among different applications being six the maximum number of application sharing links. However, the number of shared links is much higher than using other routing policies and could results in degraded applications performance. In contrast, if we focus on the other routing policies it is clear that different application shre much more links but the times those links are used are fewer. 

Other interesting result is that as we increase the number of paths in the \textit{ksp} and \textit{llskr} policies the number of applications sharing communication links increases. In particular if we compare ksp-16 and llskr-16 we can see the effect of using shorter paths by the latter that result in less application sharing links due to the more \textit{communications}. 

\section{Locality and Contiguity in Jellyfish}
\label{locality}

As we have seen, the execution of concurrent application in jellyfish causes much interference between them. As a result, the perfomance of them can be affected. This effect has been widey studied for other topologies and the solution was the introduction of locality-aware allocation policies. The goal of these policies is to maintain the task composing the applications physically close in the network, thus reducing the presence of long paths, in order to avoid that contention. 

In this section we adapt the idea of those policies to jellyfish proposing two types of allocation policies: contiguous that avoids any interference with other applications and pseudo-contiguous that relaxes the constraint of the contiguous version allowing some interference between different applications. 

\subsection{Contiguous allocation}
\label{contiguous}

\subsection{Pseudo-ontiguous allocation}
\label{contiguous}




\section{Experimental Set-up}
\label{experimental}

\subsection{Simulation environment}
\label{subsec:simulation}


\subsection{Communication patterns}
\label{subsec:communication}

\subsection{Performance metrics}
\label{subsec:performance}


\section{Analysis of the Results}
\label{analysis}

\section{Conclusiosn ans Future Work}
\label{conclusions}

%%%%%%% -- PAPER CONTENT ENDS -- %%%%%%%%

%%%%%%%%% -- BIB STYLE AND FILE -- %%%%%%%%
\bibliographystyle{ieeetr}
\bibliography{hpca16}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
